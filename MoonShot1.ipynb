{"cells":[{"cell_type":"markdown","id":"1e866085-c160-4028-babd-0b2ca9b9fdba","metadata":{"id":"1e866085-c160-4028-babd-0b2ca9b9fdba"},"source":["# Project: MoonShot - AI-powered Trading Strategy\n","\n","This notebook outlines the development of MoonShot, an Artificial intelligence (AI) system designed to assess the increase in a single stock price against a wide array of technical indicators and use this information to develop a trading pattern. We aim to achieve the following objectives:\n","\n","---\n","\n","### Select effective technical indicators:\n","We will feed a number of technical indicators into the AI as additional training parameters, it will determine correlations between indicators and the increase in stock price.\n","From these technical indicator correlations we will select the most effective techincal indicators with the most correlation to a rise in stock price. \n","\n","---\n","\n","### Train a Neural Network:\n","We will train a multilayer neural network on historical market data and the corresponding stock price history as well as the technical indicators selected. This neural network will attempt to learn and potentially improve upon the initial strategy, potentially identifying new patterns or refining existing ones.\n","\n","We will consider the model a success if it is able to increase both the Win rate by 15% while maintaining the profit percentage.\n","\n","#### Throughout this notebook, we will document the development process, including:\n","\n","- Data acquisition and preparation\n","- Feature engineering and selection\n","- Building and training the neural network\n","- Evaluating the performance of MoonShot's strategy and the trained neural network\n","\n","---\n","\n","Disclaimer: This project is for educational purposes only and should not be used for real-world trading without proper risk management and regulatory compliance. The market is inherently risky, and any trading strategy, including those involving AI, is susceptible to losses."]},{"cell_type":"markdown","id":"356208bd-1d8b-46ca-90e8-79d877dfcf2f","metadata":{"id":"356208bd-1d8b-46ca-90e8-79d877dfcf2f"},"source":["# Import Required Libraries"]},{"cell_type":"code","execution_count":3,"id":"92b16fb9-647f-4fb0-b2ce-89031e8e79dc","metadata":{"id":"92b16fb9-647f-4fb0-b2ce-89031e8e79dc"},"outputs":[],"source":["# Required libraries\n","\n","# Import the generic libraries\n","import sys\n","import pytictoc\n","\n","#Import the neural network architecture\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","#Import financial data\n","import ta\n","import yfinance as yf\n","\n","# Import data science tools\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import pandas_datareader as pdr\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import seaborn as sns\n","\n","from tickers500 import Tickers500\n","from tickerTA import Ticker\n","from tickerTA import TechnicalAnalysis"]},{"cell_type":"code","execution_count":4,"id":"4bffa765","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.2.2+cpu\n"]}],"source":["print(torch.__version__)"]},{"cell_type":"code","execution_count":null,"id":"c516862c","metadata":{},"outputs":[],"source":["print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"id":"f5a6f5c0","metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"id":"4f5ab155","metadata":{},"outputs":[],"source":["print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"id":"a7ac5f74","metadata":{},"outputs":[],"source":["\n","cuda = torch.device('cuda')\n","cuda\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device"]},{"cell_type":"code","execution_count":null,"id":"a98a3d2f","metadata":{},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"id":"78b6a5f3","metadata":{},"outputs":[],"source":["# Install torch with cuda support\n","!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"markdown","id":"0098c760-272a-4988-9d91-c640825df298","metadata":{"id":"0098c760-272a-4988-9d91-c640825df298"},"source":["---\n","# Load and Preprocess Data"]},{"cell_type":"markdown","id":"faeae68d-c55e-43f5-b1b9-910034b34c61","metadata":{"id":"faeae68d-c55e-43f5-b1b9-910034b34c61"},"source":["## 1. Initialize our Tickers500 class, update all TickerData stored CSV files, import the DataFrame we are interested in from CSV"]},{"cell_type":"code","execution_count":null,"id":"a22ec22e","metadata":{},"outputs":[],"source":["tickers500 = Tickers500()\n","ticker = tickers500.get_random_ticker()\n","ticker\n"]},{"cell_type":"code","execution_count":null,"id":"a9d7a0e9","metadata":{},"outputs":[],"source":["start_date = '2020-01-01'\n","ticker_df = tickers500.load_ticker_data_to_df(ticker, start_date)\n","ticker_df"]},{"cell_type":"markdown","id":"cd7c54f0","metadata":{},"source":["## 2. Send that DataFrame through TechnicalAnalysis class to have the technical indicators added on to a DataFrame."]},{"cell_type":"code","execution_count":null,"id":"96c1880b","metadata":{},"outputs":[],"source":["technical_analysis = TechnicalAnalysis(ticker, ticker_df)\n","technical_analysis.df_ta"]},{"cell_type":"code","execution_count":null,"id":"cfe43bc1","metadata":{},"outputs":[],"source":["technical_analysis.plot_bollinger_bands()"]},{"cell_type":"code","execution_count":null,"id":"fe4f3fce","metadata":{},"outputs":[],"source":["technical_analysis.df_ta.drop(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume'], inplace=True)"]},{"cell_type":"markdown","id":"112cebde-ab83-4697-b412-0748cc885f54","metadata":{"id":"112cebde-ab83-4697-b412-0748cc885f54"},"source":["### preprocess the main dataset\n","\n","* Drop data not required by any subsets\n","* Split the data into the X and Y sets\n","* Handle missing data\n","* scaling, normalization, and correlations\n","\n","\n","\n","\n","```\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(SimpleNN, self).__init__()\n","        #define the first layer which has neurons = <input_size> with edges per neuron = <hidden_size>\n","        self.fc0 = nn.Linear(input_size, hidden_size)\n","        #defines the hidden layers with <hidden_size> neurons and <hidden_size> outgoing edges\n","        self.fc1 = nn.Linear(hidden_size, hidden_size)\n","        # defines the second hidden layer\n","        #self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        # defines the third hidden layer\n","        #self.fc3 = nn.Linear(hidden_size, hidden_size)\n","        #defines the output layer with hidden_size connections going to output_size neurons\n","        self.fcf = nn.Linear(hidden_size, output_size)\n","        #defines the relu function used as the activation function between neurons\n","        self.relu = nn.ReLU()\n","        #defines the final function used on the forward pass\n","        self.sigmoid = nn.Sigmoid()\n","        self.softmax = nn.Softmax()\n","\n","\n","    def forward(self, x):\n","        x = self.fc0(x)\n","        x = self.relu(x)\n","\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","\n","        #x = self.fc2(x) # Second hidden layer\n","       # x = self.relu(x)\n","\n","       # x = self.fc3(x) # Third hidden layer\n","       # x = self.relu(x)\n","\n","        x = self.fcf(x)\n","        x = self.sigmoid(x)\n","        #x = self.softmax(x)\n","        #x = x.squeeze(1) # added to remove additional dimension [400, 1] added during pytorch linear layering removed for softmax\n","        return x\n","\n","## Added a second layer with lines\n","#         self.fc2a = nn.Linear(hidden_size, hidden_size)\n","#        x = self.relu(x)\n","#        x = self.fc2a(x)\n","```"]},{"cell_type":"code","execution_count":null,"id":"1be8c379","metadata":{},"outputs":[],"source":["# Two new dataframes are created, one contains all of the input features of the dataset (x), the other contains the target values (y)\n","x = technical_analysis.df_ta.drop(columns=['Adj Close'])\n","y = technical_analysis.df_ta['Adj Close']\n","\n","# The data is split into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n","\n","# The data is scaled\n","sc = StandardScaler()\n","x_train = sc.fit_transform(x_train)\n","x_test = sc.transform(x_test)\n","\n","# The data is converted to PyTorch tensors\n","x_train = torch.FloatTensor(x_train).to('cuda')\n","x_test = torch.FloatTensor(x_test).to('cuda')\n","y_train = torch.FloatTensor(y_train.to_numpy()).to('cuda')\n","y_test = torch.FloatTensor(y_test.to_numpy()).to('cuda')\n","\n","# The neural network is defined\n","class ANN(nn.Module):\n","    def __init__(self, input_features=9, hidden1=20, hidden2=20, output_features=1):\n","        super().__init__()\n","        self.f_connected1 = nn.Linear(input_features, hidden1)\n","        self.f_connected2 = nn.Linear(hidden1, hidden2)\n","        self.out = nn.Linear(hidden2, output_features)\n","    def forward(self, x):\n","        x = torch.relu(self.f_connected1(x))\n","        x = torch.relu(self.f_connected2(x))\n","        x = self.out(x)\n","        return x\n","    \n","# The model is instantiated\n","torch.manual_seed(20)\n","model = ANN()\n","model.to('cuda')\n","\n","# The loss function and optimizer are defined\n","loss_function = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n"]},{"cell_type":"code","execution_count":null,"id":"8c169f5c","metadata":{},"outputs":[],"source":["\n","# The model is trained\n","epochs = 500\n","final_losses = []\n","t = pytictoc.TicToc()\n","t.tic()\n","\n","for i in range(epochs):\n","    i += 1\n","    y_pred = model.forward(x_train)\n","    loss = loss_function(y_pred, y_train)\n","    final_losses.append(loss)\n","    if i%10 == 1:\n","        print('Epoch number: {} and the loss: {}'.format(i, loss.item()))\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","t.toc()"]},{"cell_type":"markdown","id":"a33a8e8b-45b2-4a18-b842-693674d3009b","metadata":{"id":"a33a8e8b-45b2-4a18-b842-693674d3009b"},"source":["## Training Setup"]},{"cell_type":"markdown","id":"47b0341d-252c-4782-9705-385ef965fbf3","metadata":{"id":"47b0341d-252c-4782-9705-385ef965fbf3"},"source":["> We attempt to convert the numpy and pandas series we have currently used for our dataset into tensors\n","Pandas dataframes and Numpy Arrays are used before this step for data exploration and manipulation but the deep learning library pytorch performs operations on tensors."]},{"cell_type":"code","execution_count":null,"id":"61e75887","metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","id":"1586c57d-2bec-4a3b-ac78-6b4471e0d508","metadata":{"id":"1586c57d-2bec-4a3b-ac78-6b4471e0d508"},"source":["## Training and Tuning"]},{"cell_type":"markdown","id":"8rnk3fyyNbB4","metadata":{"id":"8rnk3fyyNbB4"},"source":["> Here we define the hyperparameters of the neural network and begin training the network with those parameters. As deep learning is an iterative process- with model degredation and improvements both contributing to overall progress- this section does not contain the history of experimental training and parameter tuning that moonShot has undergone."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":5}
